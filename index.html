<!DOCTYPE HTML>
<!--
	Visualize by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>Laura (Wendlandt) Burdick</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

        <!-- Bootstrap core CSS -->
        <link href="dist/css/bootstrap.min.css" rel="stylesheet">

		<link rel="stylesheet" href="assets/css/main.css" />
        <link href="https://fonts.googleapis.com/css?family=Bilbo+Swash+Caps" rel="stylesheet" type="text/css">	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
                    <div id="top">
                        <div id="left">
						<span class="avatar"><img src="images/laura.jpg" alt="" /></span>
                        </div>
                        <div id="right">
                        <h1 id="laura">Laura (Wendlandt) Burdick</h1>

                        <ul class="icons">
							<li><a href="mailto:wenlaura@umich.edu" target="_top" class="icon icon-fa style2 fa-envelope-o"><span class="label">E-mail</span></a></li>
                            <li><a href="https://twitter.com/wenlaura314" target="_blank" class="icon icon-fa style2 fa-twitter"><span class="label">twitter</span></a></li>
							<li><a href="https://www.linkedin.com/in/laura-wendlandt-burdick-6247a469/" target="_blank" class="icon icon-fa style2 fa-linkedin"><span class="label">Linked In</span></a></li>
                            <li><a href="https://scholar.google.com/citations?hl=en&user=bNocrTgAAAAJ" target="_blank" class="icon icon-ai style2 ai ai-google-scholar"><span class="label">Google Scholar</span></a></li>
							<li><a href="https://github.com/laura-burdick" target="_blank" class="icon icon-fa style2 fa-github"><span class="label">Github</span></a></li>
						</ul>
                        </div>

                        </right>
                    </div>
                    </header>

                    <div id="body">
                        <div class="navigation">
                        <hr class="navH0" />
                        <h2><a href="index.html" class="research">Research</a>
                        <a href="teaching.html" class="research">Teaching</a>
                        <a href="outreach.html" class="research">Outreach</a>
						<a href="misc.html" class="research">Misc.</a>
						<a href="Laura_Burdick_CV.pdf" target="_blank">CV (pdf)</a></h2>
                        <hr class="navH" />
                        </div>

						<h2>I am a PhD candidate in <a href="https://www.cse.umich.edu/" target="_blank">Computer Science and Engineering</a> at the <a href="https://umich.edu/" target="_blank">University of Michigan</a>, where I am a part of the <a href="http://lit.eecs.umich.edu/" target="_blank">LIT research group</a> (part of the <a href="http://ai.eecs.umich.edu/" target="_blank">Michigan AI Lab</a>), supervised by <a href="https://web.eecs.umich.edu/~mihalcea/" target="_blank">Dr. Rada Mihalcea</a>. I earned my bachelor's degree in computer science at <a href="http://www.gcc.edu/" target="_blank">Grove City College</a> in 2015 and my Master's degree from University of Michigan in 2017.</h2>
						<h2>My research is in the area of natural language processing, where I am interested in word embeddings, computational social science, machine learning techniques, and multimodal problems with vision and language.</h2>

                        <h1 id="publications">Publications</h1>

						<h2>Identifying Visible Actions in Lifestyle Vlogs</h2>
						<p id="authors">Oana Ignat, <u>Laura Burdick</u>, <a href="https://www.cs.princeton.edu/~jiadeng/" target="_blank">Jia Deng</a>, <a href="https://web.eecs.umich.edu/~mihalcea/" target="_blank">Rada Mihalcea</a>
						</br><i>ACL, 2019</i></p>
						<p>
							<a href="papers/Ignat.HumanActionDetection_2019.pdf" target="_blank" class="btn btn-sm btn-outline-secondary" role="button">PDF</a>	
                            <a data-toggle="collapse" data-target="#abstract4" aria-expanded="false" aria-controls="abstract4" class="right-button btn btn-sm btn-outline-secondary" role="button">Abstract</a>
                            <a data-toggle="collapse" data-target="#bibtex4" aria-expanded="false" aria-controls="bibtex4" class="right-button btn btn-sm btn-outline-secondary" role="button">BibTeX</a>
						</p>
                        <div class="collapse" id="abstract4"><p id="abstract"><i>
                        We consider the task of identifying human actions visible in online videos. We focus on the
						widely spread genre of lifestyle vlogs, which
						consist of videos of people performing actions
						while verbally describing them. Our goal is to
						identify if actions mentioned in the speech description of a video are visually present. We
						construct a dataset with crowdsourced manual
						annotations of visible actions, and introduce a
						multimodal algorithm that leverages information derived from visual and linguistic clues to
						automatically infer which actions are visible in
						a video. We demonstrate that our multimodal
						algorithm outperforms algorithms based only
						on one modality at a time.
						</i></p></div>
                        <div class="collapse" id="bibtex4"><p id="bibtex">
                            @article{Ignat19Actions,</br>
                              author = {Ignat, Oana and Laura Burdick and Jia Deng and Rada Mihalcea},</br>
                              title = {Identifying Visible Actions in Lifestyle Vlogs
							  },</br>
                              journal = {ACL},</br>
                              year = {2019}</br>
                            }
                        </p></div>

                        <h2>Factors Influencing the Surprising Instability of Word Embeddings</h2>
                        <p id="authors"><u>Laura Wendlandt</u>, <a href="http://jkk.name/" target="_blank">Jonathan K. Kummerfeld</a>, <a href="https://web.eecs.umich.edu/~mihalcea/" target="_blank">Rada Mihalcea</a>
                        </br><i>NAACL-HLT, 2018</i></p>
						<p id="comment">I wrote a <a href="https://michiganaiblog.github.io/2018/07/23/Word-Embeddings-and-how-they-vary/" target="_blank">blog post</a> (Michigan AI Blog) for the general public about this work.</p>
                        <p>
                            <a href="papers/naacl18embeddings.pdf" target="_blank" class="btn btn-sm btn-outline-secondary" role="button">PDF</a>
                            <a data-toggle="collapse" data-target="#abstract3" aria-expanded="false" aria-controls="abstract3" class="right-button btn btn-sm btn-outline-secondary" role="button">Abstract</a>
                            <a data-toggle="collapse" data-target="#bibtex3" aria-expanded="false" aria-controls="bibtex3" class="right-button btn btn-sm btn-outline-secondary" role="button">BibTeX</a>
                            <a href="https://github.com/wendlandt/embeddingStability" target="_blank" class="right-button btn btn-sm btn-outline-secondary" role="button">Code</a>
                            <a data-toggle="collapse" data-target="#citations3" aria-expanded="false" aria-controls="citations3" class="right-button btn btn-sm btn-outline-secondary" role="button">Citations (10)</a>
                            <a href="papers/naacl18embeddings_poster.pdf" target="_blank" class="right-button btn btn-sm btn-outline-secondary" role="button">Poster</a>
                            <a href="papers/naacl18embeddings_slides.pdf" target="_blank" class="right-button btn btn-sm btn-outline-secondary" role="button">Slides</a>
                        </p>
                        <div class="collapse" id="abstract3"><p id="abstract"><i>
                            Despite the recent popularity of word embedding methods, there is only a small body of work exploring the limitations of these representations. In this paper, we consider one aspect of embedding spaces, namely their stability. We show that even relatively high frequency words (100-200 occurrences) are often unstable. We provide empirical evidence for how various factors contribute to the stability of word embeddings, and we analyze the effects of stability on downstream tasks.
                        </i></p></div>
                        <div class="collapse" id="bibtex3"><p id="bibtex">
                            @article{Wendlandt18Surprising,</br>
                              author = {Wendlandt, Laura and Kummerfeld, Jonathan K. and Mihalcea, Rada},</br>
                              title = {Factors Influencing the Surprising Instability of Word Embeddings},</br>
							  pages = "2092--2102",</br>
							  url = "https://www.aclweb.org/anthology/N18-1190",</br>
							  doi = "10.18653/v1/N18-1190",</br>
                              booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",</br>
                              year = {2018}</br>
                            }
                        </p></div>
						<div class="collapse" id="citations3">
						<p id="abstract">
						Hellrich, et al. "<a href="https://arxiv.org/abs/1806.08115" target="_blank">Modeling Word Emotion in Historical Language: Quantity Beats Supposed Stability in Seed Word Selection.</a>" <i>Workshop on Language Technologies for the Socio-Economic Sciences and Humanities (LaTeCH-CLfL).</i> 2019.
						</br></br>
						Pierrejean and Tanguy. "<a href="https://www.aclweb.org/anthology/papers/W/W19/W19-0510/" target="_blank">Investigating the Stability of Concrete Nouns in Word Embeddings.</a>" <i>International Conference on Computational Semantics.</i> 2019.
						</br></br>
						Heyman and Heyman. "<a href="https://journals.sagepub.com/doi/full/10.1177/1747021819830949" target="_blank">Can prediction-based distributional semantic models predict typicality?</a>" <i>Quarterly Journal of Experimental Psychology.</i> 2019.
						</br></br>
						Zhou, Chunting et al. "<a href="https://arxiv.org/abs/1904.02343" target="_blank">Density Matching for Bilingual Word Embedding.</a>" <i>NAACL-HLT.</i> 2019.
						</br></br>
						Viegas, Felipe, et al. "<a href="https://dl.acm.org/citation.cfm?id=3291032" target="_blank">CluWords: Exploiting Semantic Word Clustering Representation for Enhanced Topic Modeling</a>" <i>Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining.</i> 2019.
						</br></br>
						K&ouml;per. <a href="https://elib.uni-stuttgart.de/bitstream/11682/10130/1/koeper_thesis.pdf" target="_blank"><i>Computational approaches for German
						particle verbs: compositionality, sense
						discrimination and non-literal
						language.</i></a> Diss. Universit&auml;t Stuttgart, 2018. Web. November 26, 2018.
						</br></br>
						M&uuml;ller and Strube. "<a href="http://www.aclweb.org/anthology/C18-2012" target="_blank">Transparent, Efficient, and Robust Word Embedding Access with WOMBAT.</a>" <i>COLING: System Demonstrations.</i> 2018.
						</br></br>
						Rogers, Anna, et al. "<a href="http://www.cs.uml.edu/~arum/publications/Rogers_Ananthakrishna_Rumshisky_COLING2018_LDT.pdf" target="_blank">What’s in Your Embedding, And How It Predicts Task Performance.</a>" <i>COLING.</i> 2018.
						</br></br>
						Regneri, Michaela, et al. "<a href="https://arxiv.org/abs/1807.07404" target="_blank">Analyzing Hypersensitive AI: Instability in Corporate-Scale Machine Learning.</a>" <i>IJCAI-ECAI Workshop on Explainable AI.</i> 2018.
						</br></br>
						Karpinska, Marzena, et al. "<a href="http://www.aclweb.org/anthology/W18-2905" target="_blank">Subcharacter Information in Japanese Embeddings: When Is It Worth It?</a>" <i>Workshop on the Relevance of Linguistic Structure in Neural Architectures for NLP (RepL4NLP).</i> 2018.
						</p></div>

                        <h2>Multimodal Analysis and Prediction of Latent User Dimensions</h2>
                        <p id="authors"><u>Laura Wendlandt</u>, <a href="https://web.eecs.umich.edu/~mihalcea/" target="_blank">Rada Mihalcea</a>, <a href="https://ryanb.cc/" target="_blank">Ryan L. Boyd</a>, <a href="https://liberalarts.utexas.edu/psychology/faculty/pennebak" target="_blank">James W. Pennebaker</a>
                        </br><i>SocInfo, 2017</i></p>
                        <p>
                            <a href="http://web.eecs.umich.edu/~mihalcea/papers/wendlandt.socinfo17.pdf" target="_blank" class="btn btn-sm btn-outline-secondary" role="button">PDF</a>
                            <a data-toggle="collapse" data-target="#abstract2" aria-expanded="false" aria-controls="abstract2" class="right-button btn btn-sm btn-outline-secondary" role="button">Abstract</a>
                            <a data-toggle="collapse" data-target="#bibtex2" aria-expanded="false" aria-controls="bibtex2" class="right-button btn btn-sm btn-outline-secondary" role="button">BibTeX</a>
                            <a href="https://github.com/wendlandt/imagesPersonality" target="_blank" class="right-button btn btn-sm btn-outline-secondary" role="button">Code</a>
                            <a data-toggle="collapse" data-target="#citations2" aria-expanded="false" aria-controls="citations2" class="right-button btn btn-sm btn-outline-secondary" role="button">Citations (1)</a>
                            <a href="papers/socinfo17multimodal_poster.pdf" target="_blank" class="right-button btn btn-sm btn-outline-secondary" role="button">Poster</a>
                            <a href="papers/socinfo17multimodal_slides.pdf" target="_blank" class="right-button btn btn-sm btn-outline-secondary" role="button">Slides</a>
                        
						</p>
                        <div class="collapse" id="abstract2"><p id="abstract"><i>
                            Humans upload over 1.8 billion digital images to the internet each day,  yet the relationship between the images that a person shares with others and his/her psychological characteristics remains poorly understood. In the current research, we analyze the relationship between images, captions, and the latent demographic/psychological dimensions of personality and gender. We consider a wide range of automatically extracted visual and textual features of images/captions that are shared by a large sample of individuals (N ~ 1,350). Using correlational methods, we identify several visual and textual properties that show strong relationships with individual differences between participants. Additionally, we explore the task of predicting user attributes using a multimodal approach that simultaneously leverages images and their captions. Results from these experiments suggest that images alone have significant predictive power and, additionally, multimodal methods outperform both visual features and textual features in isolation when attempting to predict individual differences.
                        </i></p></div>
                        <div class="collapse" id="bibtex2"><p id="bibtex">
                            @inproceedings{Wendlandt17Multimodal,</br>
                             author = {Wendlandt, Laura and Mihalcea, Rada and Boyd, Ryan L. and Pennebaker, James W.},</br>
                             title = {Multimodal Analysis and Prediction of Latent User Dimensions},</br>
                             booktitle = {Proceedings of the 9th International Conference on Social Informatics (SocInfo 2017)},</br>
                             year = {2017}</br>
                            }
                        </p></div>
						<div class="collapse" id="citations2">
						<p id="abstract">
						Carmona, Miguel Ángel Álvarez. <i><a href="https://inaoe.repositorioinstitucional.mx/jspui/bitstream/1009/1686/1/AlvarezCaMA.pdf" target="_blank">Author Profiling in Social Media with Multimodal Information.</a></i> Diss. Instituto Nacional de Astrofísica, Óptica y Electrónica, 2019. Web. March 28, 2019.
						</p></div>

                        <h2>Data Science in Service of Performing Arts: Applying Machine Learning to Predicting Audience Preferences</h2>
                        <p id="authors"><a href="https://www.cc.gatech.edu/~jabernethy9/" target="_blank">Jacob Abernethy</a>,  <a href="https://robotics.umich.edu/profile/cyrus-anderson/" target="_blank">Cyrus Anderson</a>,  Chengyu Dai,  John Dryden,  <a href="http://www-personal.umich.edu/~ericmsch/?_ga=2.242343234.1331392260.1559841628-1075510540.1544457456" target="_blank">Eric Schwartz</a>,  Wenbo Shen,  <a href="http://www-personal.umich.edu/~stroud/" target="_blank">Jonathan Stroud</a>, <u>Laura Wendlandt</u>, Sheng Yang, Daniel Zhang
                        </br><i>Bloomberg Data for Good Exchange, 2016</i></p>
                        <p>
                            <a href="papers/2016_DataforGood_UMS.pdf" target="_blank" class="btn btn-sm btn-outline-secondary" role="button">PDF</a>
                            <a data-toggle="collapse" data-target="#abstract1" aria-expanded="false" aria-controls="abstract1" class="right-button btn btn-sm btn-outline-secondary" role="button">Abstract</a>
                            <a data-toggle="collapse" data-target="#bibtex1" aria-expanded="false" aria-controls="bibtex1" class="right-button btn btn-sm btn-outline-secondary" role="button">BibTeX</a>
							<a data-toggle="collapse" data-target="#citations1" aria-expanded="false" aria-controls="citations1" class="right-button btn btn-sm btn-outline-secondary">Citations (1)</a>
                        </p>
                        <div class="collapse" id="abstract1"><p id="abstract"><i>
                            Performing arts organizations aim to enrich their communities through the arts. To do this, they strive to match their performance offerings to the taste of those communities. Success relies on understanding audience preference and predicting their behavior. Similar to most e-commerce or digital entertainment firms, arts presenters need to recommend the right performance to the right customer at the right time. As part of the Michigan Data Science Team (MDST), we partnered with the University Musical Society (UMS), a non-profit performing arts presenter housed in the University of Michigan, Ann Arbor. We are providing UMS with analysis and business intelligence, utilizing historical individual-level sales data. We built a recommendation system based on collaborative filtering, gaining insights into the artistic preferences of customers, along with the similarities between performances. To better understand audience behavior, we used statistical methods from customer-base analysis. We characterized customer heterogeneity via segmentation, and we modeled customer cohorts to understand and predict ticket purchasing patterns. Finally, we combined statistical modeling with natural language processing (NLP) to explore the impact of wording in program descriptions. These ongoing efforts provide a platform to launch targeted marketing campaigns, helping UMS carry out its mission by allocating its resources more efficiently. Celebrating its 138th season, UMS is a 2014 recipient of the National Medal of Arts, and it continues to enrich communities by connecting world-renowned artists with diverse audiences, especially students in their formative years. We aim to con tribute to that mission through data science and customer analytics.
                        </i></p></div>
                        <div class="collapse" id="bibtex1"><p id="bibtex">
                            @inproceedings{Abernethy2016Data,</br>
                             author = {Abernethy, J. and C. Anderson and C. Dai and J. Dryden and E. Schwartz and W. Shen and J. Stroud and L. Wendlandt and S. Yang and D. Zhang},</br>
                             title = {Data Science in Service of Performing Arts: Applying Machine Learning to Predicting Audience Preferences},</br>
                             booktitle = {Bloomberg Data for Good Exchange},</br>
                             year = {2016},</br>
                            }
                        </p></div>
						<div class="collapse" id="citations1">
						<p id="abstract">
						Farahi and Stroud. "<a href="https://ieeexplore.ieee.org/abstract/document/8439915/" target="_blank">The Michigan Data Science Team: A Data Science Education Program with Significant Social Impact.</a>" <i>IEEE Data Science Workshop.</i> 2018.
						</p></div>

				</div>
				
				<!-- Footer -->
					<footer id="footer">
						<p><b>E-mail</b>: <a href="mailto:wenlaura@umich.edu" target="_top">wenlaura@umich.edu</a><br /><b>Physical Address</b>: <a href="https://www.google.com/maps/place/2260+Hayward+St,+Ann+Arbor,+MI+48109/@42.2930177,-83.718566,17z/data=!3m1!4b1!4m5!3m4!1s0x883cae86f7d56117:0x9c2faa37c123498c!8m2!3d42.2930138!4d-83.716372" target="_blank">2260 Hayward Street, Ann Arbor, MI 48109, USA</a></br />&copy; 2018 Laura (Wendlandt) Burdick. Design: <a href="http://templated.co">TEMPLATED</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
            <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="assets/js/vendor/jquery.min.js"><\/script>')</script>
        <script src="dist/js/bootstrap.min.js"></script>

            <script src="dist/js/bootstrap.min.js"></script>
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
